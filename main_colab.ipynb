{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bad6b990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c67533-193e-4378-b5ae-c4f26c132a05"
      },
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ],
      "id": "bad6b990",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi2YxDt0qmzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f973db-bf8b-42b9-d5e5-2bcb76d1f637"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "yi2YxDt0qmzK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7aa4b99"
      },
      "source": [
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install pandas\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install icecream\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install nltk\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install plotly\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install pytorch_pretrained_bert pytorch-nlp\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install keras\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install tensorflow\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install transformers\n",
        "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install ipynb"
      ],
      "id": "c7aa4b99",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkrfx8tZq6Ig"
      },
      "source": [
        "!pip install -qq ipynb\n",
        "!pip install -qq plotly\n",
        "!pip install -qq import-ipynb\n",
        "!pip install -qq icecream\n",
        "!pip install -qq transformers"
      ],
      "id": "tkrfx8tZq6Ig",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f7700ca"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rn\n",
        "from tqdm.notebook import tqdm\n",
        "from icecream import ic \n",
        "\n",
        "# imports from shudima\n",
        "import torch\n",
        "from transformers import BertTokenizer\n"
      ],
      "id": "5f7700ca",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "868a6956"
      },
      "source": [
        "# # preprocessing for BERT\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# tokenizer.tokenize('Hi my nambe is Dima')\n",
        "# train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train['text']))"
      ],
      "id": "868a6956",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1987c648"
      },
      "source": [
        "# from ipynb.fs.full.utils import *\n",
        "# from ipynb.fs.full.datasets import *\n",
        "# from ipynb.fs.full.architectures import *\n",
        "# from ipynb.fs.full.train_test import *"
      ],
      "id": "1987c648",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhPTB7squWp9",
        "outputId": "0fbfd36a-8e4b-4012-beae-f539f90af858"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "id": "KhPTB7squWp9",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilIYy3hKrJZ8",
        "outputId": "56ac9915-9c56-4109-adf2-6afd8405399a"
      },
      "source": [
        "!pwd\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/Spring\\ 21/NLP/Humour-Detection-2021\n",
        "!ls\n",
        "import import_ipynb\n",
        "from utils import *\n",
        "from datasets import *\n",
        "from architectures import *\n",
        "from train_test import *\n",
        "import importlib"
      ],
      "id": "ilIYy3hKrJZ8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Colab Notebooks/Spring 21/NLP/Humour-Detection-2021\n",
            "architectures.ipynb  main-dump.ipynb\t    results_publictest_2.csv\n",
            "data\t\t     model_weights\t    results_publictest.csv\n",
            "data-analysis.ipynb  pandas-syntax-2.ipynb  train_test.ipynb\n",
            "datasets.ipynb\t     pandas-syntax.ipynb    utils.ipynb\n",
            "main_colab.ipynb     README.md\n",
            "importing Jupyter notebook from utils.ipynb\n",
            "importing Jupyter notebook from datasets.ipynb\n",
            "importing Jupyter notebook from architectures.ipynb\n",
            "importing Jupyter notebook from train_test.ipynb\n",
            "CrossEntropyLoss()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmw7UxWg2f8h"
      },
      "source": [
        "#init \n",
        "train_count = 8000 #8000\n",
        "# test_count = \n",
        "  \n",
        "MAX_SENTENCE_LENGTH = 128 #colbert=20\n",
        "MAX_SENTENCES = 5\n",
        "MAX_LENGTH = 100"
      ],
      "id": "mmw7UxWg2f8h",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z75pbqn5uauW",
        "outputId": "ae12253c-2f9c-4d48-c39a-19809a6f27a7"
      },
      "source": [
        "#===============================================================================\n",
        "# Device Selction (GPU/CPU) and Seed Initialization\n",
        "#===============================================================================\n",
        "# args parameters\n",
        "no_cuda=False\n",
        "seed =1\n",
        "test_model = False\n",
        "\n",
        "ic(torch.cuda.is_available())\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs   = {'num_workers': 32, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if(use_cuda):\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.backends.cudnn.benchmark = True\n",
        "np.random.seed(seed)\n",
        "\n",
        "print(\"\\nDevice: \" + str(device) +\"; Seed: \"+str(seed))\n"
      ],
      "id": "Z75pbqn5uauW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| torch.cuda.is_available(): True\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Device: cuda; Seed: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "187df154",
        "outputId": "d59c0b03-e76f-4f7a-ca06-c9cb84e0fbf6"
      },
      "source": [
        "#===============================================================================\n",
        "# Dataset and Model Selection\n",
        "#===============================================================================\n",
        "\n",
        "# if seq length is 128 batch size should be 32\n",
        "traindata = torch.utils.data.DataLoader(dataset= Hahackathon(\"data/train.csv\"\n",
        ", basenet= 'bert')\n",
        ", batch_size= 32, shuffle= True,  **kwargs)\n",
        "\n",
        "valdata = torch.utils.data.DataLoader(dataset= Hahackathon(\"data/dev.csv\"  \n",
        ", basenet= 'bert' )\n",
        ", batch_size= 128, shuffle= False, **kwargs)\n",
        "\n",
        "testdata = torch.utils.data.DataLoader(dataset= Hahackathon(\"data/gold-test-27446.csv\" \n",
        ", basenet= 'bert') \n",
        ", batch_size= 128, shuffle= False, **kwargs)\n",
        "\n",
        "# ic(\"Size of the dataset\",len(traindata.dataset))\n",
        "# model = multitask_fc('bert', n_outputs=2)\n",
        "model = multitask_fc('bert', n_outputs=2) #workaround: architectures - multitask_fc - temporal=True\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "\tprint(\"Using {} GPUs! \\n\".format(torch.cuda.device_count()))\n",
        "\tmodel = torch.nn.DataParallel(model)\n",
        " \n",
        "model = model.to(device)\n"
      ],
      "id": "187df154",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sampled input from the file: data/train.csv\n",
            "   id  ... offense_rating\n",
            "0   1  ...            0.2\n",
            "1   2  ...            1.1\n",
            "2   3  ...            2.4\n",
            "3   4  ...            0.0\n",
            "4   5  ...            0.1\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "Tokenizer: bert-base-uncased\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sampled input from the file: data/dev.csv\n",
            "     id  ... offense_rating\n",
            "0  8001  ...           1.70\n",
            "1  8002  ...           0.00\n",
            "2  8003  ...           1.15\n",
            "3  8004  ...           3.75\n",
            "4  8005  ...           2.25\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "Tokenizer: bert-base-uncased\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sampled input from the file: data/gold-test-27446.csv\n",
            "     id  ... offense_rating\n",
            "0  9001  ...           0.90\n",
            "1  9002  ...           0.35\n",
            "2  9003  ...           0.10\n",
            "3  9004  ...           0.00\n",
            "4  9005  ...           0.35\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "Tokenizer: bert-base-uncased\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Base architecture: bert-base-uncased\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42e29a4a",
        "outputId": "f353fd89-6437-4f57-ae6f-33449240b0e0"
      },
      "source": [
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "ce_criterion  = torch.nn.CrossEntropyLoss()\n",
        "ic(ce_criterion)\n",
        "\n",
        "def concat_output1(output, device):\n",
        "  temp = torch.tensor([]).to(device)\n",
        "\n",
        "  if output.shape[1] == 2:\n",
        "      # ic()\n",
        "      temp = torch.argmax(output[:, 0:2], dim=1).view(-1,1)\n",
        "      return temp\n",
        "\n",
        "  # temp = torch.argmax(output[:, 0:2], dim=1).view(-1,1)\n",
        "  # temp = torch.cat((temp, torch.argmax(output[:, 2:4], dim= 1).view(-1,1)), dim= 1)\n",
        "  # temp = torch.cat((temp, output[:, 4].view(-1,1)), dim= 1)\n",
        "  # temp = torch.cat((temp, output[:, 5].view(-1,1)), dim= 1)\n",
        "  return temp\n",
        "\n",
        "def loss_func1(output, target, device):\n",
        "\n",
        "  humor_id = (target[:, 0]==1)\n",
        "  target   = target.float()\n",
        "  \n",
        "  loss1 = ce_criterion(output[:, 0:2], target[:, 0].long())\n",
        "  loss=loss1\n",
        "  \n",
        "  # this block of generating temp is verified throughly\n",
        "  temp = concat_output1(output, device)\n",
        "  temp = temp.detach()\n",
        "  return loss, temp\n",
        "\n",
        "def train1(model, dataloader, optimizer, device):\n",
        "  model.train()\n",
        "  train_loss = AverageMeter()\n",
        "\n",
        "  for batch_id, batch_data in enumerate(dataloader):\n",
        "      data       = batch_data[0]\n",
        "      target     = batch_data[1].to(device)\n",
        "\n",
        "      input_id   = data[0].to(device).squeeze()\n",
        "      mask_id    = data[1].to(device).squeeze()\n",
        "      segment_id = data[2].to(device).squeeze()\n",
        "\n",
        "      output = model(input_id, mask_id, segment_id)\n",
        "      \n",
        "      loss, _ = loss_func1(output, target, device= device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss.update(loss.item(), target.shape[0])\n",
        "\n",
        "  return train_loss.avg\n",
        "\n",
        "def test1(model, dataloader, device):\n",
        "  model.eval()\n",
        "  test_loss = AverageMeter()\n",
        "  outputs   = torch.tensor([]).to(device)\n",
        "  targets   = torch.tensor([]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_id, batch_data in enumerate(dataloader):\n",
        "      data       = batch_data[0]\n",
        "      target     = batch_data[1].to(device)\n",
        "      \n",
        "      token_id   = data[0].to(device).squeeze()\n",
        "      mask_id    = data[1].to(device).squeeze()\n",
        "      segment_id = data[2].to(device).squeeze()\n",
        "\n",
        "      output     = model(token_id, mask_id, segment_id)\n",
        "\n",
        "      loss, temp = loss_func1(output, target, device= device)\n",
        "      outputs    = torch.cat((outputs, temp)  , 0)\n",
        "      targets    = torch.cat((targets, target), 0)\n",
        "\n",
        "      test_loss.update(loss.item(), target.shape[0])\n",
        "\n",
        "  outputs = outputs.cpu().numpy()\n",
        "  targets = targets.cpu().numpy()\n",
        "\n",
        "  humor_fscore          = f1_score          (targets[:, 0], outputs[:, 0])\n",
        "  # controversy_fscore    = f1_score          (targets[:, 1], outputs[:, 1])\n",
        "  humor_acc             = accuracy_score    (targets[:, 0], outputs[:, 0])\n",
        "  # controversy_acc       = accuracy_score    (targets[:, 1], outputs[:, 1])\n",
        "  # humor_rating_rmse     = mean_squared_error(targets[:, 2], outputs[:, 2], squared= False)\n",
        "  # offensive_rating_rmse = mean_squared_error(targets[:, 3], outputs[:, 3], squared= False)\n",
        "\n",
        "  return test_loss.avg, [humor_fscore, humor_acc] #, controversy_fscore, controversy_acc, humor_rating_rmse, offensive_rating_rmse]\n",
        "\n",
        "def get_result_on_evaldata1(model, dataloader, filename, device):\n",
        "  model.eval()\n",
        "  outputs  = torch.tensor([]).to(device)\n",
        "  text_ids = torch.tensor([]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_id, batch_data in enumerate(dataloader):\n",
        "      data = batch_data[0]\n",
        "      text_id    = batch_data[1].to(device)\n",
        "\n",
        "      token_id   = data[0].to(device).squeeze()\n",
        "      mask_id    = data[1].to(device).squeeze()\n",
        "      segment_id = data[2].to(device).squeeze()\n",
        "\n",
        "      output = model(token_id, mask_id, segment_id)\n",
        "\n",
        "      temp     = concat_output1(output, device)\n",
        "      outputs  = torch.cat((outputs, temp), 0)\n",
        "      text_ids = torch.cat((text_ids, text_id), 0)\n",
        "\n",
        "  ic(outputs.shape, text_ids.shape)\n",
        "  outputs  = outputs.cpu().numpy()\n",
        "  text_ids = text_ids.cpu().numpy()\n",
        "\n",
        "  results = np.hstack((text_ids, outputs))\n",
        "  df      = pd.DataFrame(data    = results,  \n",
        "                          columns = ['id', 'is_humor', 'humor_controversy', 'humor_rating', 'offense_rating']) \n",
        "\n",
        "  df['id']                = (df['id']).astype('int')\n",
        "  df['is_humor']          = (df['is_humor']).astype('int')\n",
        "  # df['humor_controversy'] = (df['humor_controversy']).astype('int')\n",
        "  df = df[['id', 'is_humor']]   #, 'humor_rating', 'humor_controversy', 'offense_rating']]\n",
        "\n",
        "  df.to_csv(filename, index = False)\n",
        "  ic(\"Result file is saved to {}\".format(filename))"
      ],
      "id": "42e29a4a",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| ce_criterion: CrossEntropyLoss()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec3589bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "540e0029-b381-4071-93db-224549212183"
      },
      "source": [
        "#===============================================================================\n",
        "# Start Training , Configure params\n",
        "#===============================================================================\n",
        "learning_rate=0.00002 #0.01 to 0.00002\n",
        "start_epoch = 1\n",
        "epochs = 10 #10 to 30\n",
        "train_loss_arr = []\n",
        "val_loss_arr = []\n",
        "metrics_arr = [] #f1 , accuracy\n",
        "\n",
        "if not test_model:\n",
        "\n",
        "  ic(\"Training starts\")\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "  for ep in range(start_epoch, start_epoch+epochs):\n",
        "      train_loss = train1(model, traindata, optimizer, device)\n",
        "      val_loss, metrics = test1(model, valdata, device)\n",
        "\n",
        "      ic(train_loss)\n",
        "      train_loss_arr.append(train_loss)\n",
        "      val_loss_arr.append(val_loss)\n",
        "      metrics_arr.append(metrics)\n",
        "\n",
        "  #===============================================================================\n",
        "  # Configure Run Iteration and Model Save\n",
        "  #===============================================================================\n",
        "  run_iter = 5 #iterations you ran the model\n",
        "  save_dir = os.path.join('model_weights', 'run_{}'.format(run_iter))\n",
        "  create_folder(save_dir)\n",
        "  save_path = os.path.join(save_dir, \"epoch_{}\".format(epochs) + \".pth\")\n",
        "  save_model(model, optimizer, opt= None, epoch= epochs, save_file= save_path)\n",
        "  model = model.to(device)\n",
        "\n",
        "  #===============================================================================\n",
        "  # Plot graphs\n",
        "  #=============================================================================== \n",
        "  print('Final train loss: ', train_loss_arr[-1])\n",
        "  print(' val loss: ', val_loss_arr[-1])\n",
        "  print('val F1 score: ', metrics_arr[-1][0])\n",
        "  print('val Accuracy: ', metrics_arr[-1][1])\n",
        "\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  x_axis = list(range(1, len(train_loss_arr)+1)) #epochs\n",
        "  y_axis = list(train_loss_arr)\n",
        "\n",
        "  fig = go.Figure(data = go.Scatter(x= x_axis, y= y_axis))\n",
        "  fig.update_layout(title='train loss',\n",
        "                    xaxis_title='epochs',\n",
        "                    yaxis_title='loss')\n",
        "  fig.show(renderer=\"colab\")\n",
        "\n",
        "  y2_axis = np.array(metrics_arr)\n",
        "  fig2 = go.Figure()\n",
        "  fig2.add_trace(go.Scatter(x= x_axis, y= y2_axis[:,0],\n",
        "                      mode='lines',\n",
        "                      name='f1-score'))\n",
        "  fig2.add_trace(go.Scatter(x= x_axis, y= y2_axis[:,1],\n",
        "                      mode='lines+markers',\n",
        "                      name='accuracy'))\n",
        "  fig2.update_layout(title='performance',\n",
        "                    xaxis_title='epochs',\n",
        "                    yaxis_title='metrics')\n",
        "  fig2.show(renderer=\"colab\")\n"
      ],
      "id": "ec3589bd",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| 'Training starts'\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "ic| train_loss: 0.24715228767693043\n",
            "ic| train_loss: 0.0932025688495487\n",
            "ic| train_loss: 0.043742132410407066\n",
            "ic| train_loss: 0.02659177664294839\n",
            "ic| train_loss: 0.012507175004575401\n",
            "ic| train_loss: 0.016231738247442992\n",
            "ic| train_loss: 0.0047961108456365765\n",
            "ic| train_loss: 0.007669825210468844\n",
            "ic| train_loss: 0.006795325733837672\n",
            "ic| train_loss: 0.014689894914044998\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating directory model_weights/run_5\n",
            "Final train loss:  0.014689894914044998\n",
            " val loss:  0.48314259481430055\n",
            "val F1 score:  0.9200930954228085\n",
            "val Accuracy:  0.897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"fb933b3d-4f12-4c86-987f-075bdae30135\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"fb933b3d-4f12-4c86-987f-075bdae30135\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'fb933b3d-4f12-4c86-987f-075bdae30135',\n",
              "                        [{\"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.24715228767693043, 0.0932025688495487, 0.043742132410407066, 0.02659177664294839, 0.012507175004575401, 0.016231738247442992, 0.0047961108456365765, 0.007669825210468844, 0.006795325733837672, 0.014689894914044998]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"train loss\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fb933b3d-4f12-4c86-987f-075bdae30135');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"967d2959-50e2-4e56-96bf-395feaa57e51\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"967d2959-50e2-4e56-96bf-395feaa57e51\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '967d2959-50e2-4e56-96bf-395feaa57e51',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"f1-score\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.9267139479905439, 0.9212410501193319, 0.9172361427486712, 0.911042944785276, 0.9100371747211896, 0.9229583975346687, 0.9101707498144024, 0.9133489461358313, 0.9082125603864735, 0.9200930954228085]}, {\"mode\": \"lines+markers\", \"name\": \"accuracy\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.907, 0.901, 0.891, 0.884, 0.879, 0.9, 0.879, 0.889, 0.886, 0.897]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"performance\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"metrics\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('967d2959-50e2-4e56-96bf-395feaa57e51');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J3bRAZZC1u3"
      },
      "source": [
        "#===============================================================================\n",
        "# Generate prediction file on testdata\n",
        "#===============================================================================\n",
        "ic(\"Generating prediction file for post-evaluation phase\")\n",
        "# filename   = \"results_publictest_2.csv\" \n",
        "save_path_test = os.path.join(save_dir, \"epoch_{}\".format(epochs) + \"results_publictest.csv\")\n",
        "# model = model.to(device)\n",
        "get_result_on_evaldata1(model, testdata, save_path_test, device= device)"
      ],
      "id": "8J3bRAZZC1u3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCTks0JG44Sw",
        "outputId": "35f8b155-6508-4f0f-94bb-54494a80f994"
      },
      "source": [
        "#===============================================================================\n",
        "# Load a saved movel\n",
        "#===============================================================================\n",
        "# path = \"model_weights/run_4/epoch_10.pth\"\n",
        "# !ls model_weights/run_4/\n",
        "# !pwd\n",
        "model, start_epoch = load_weights(model, path)\n",
        "ic(start_epoch)\n",
        "# model = model.to(device)"
      ],
      "id": "nCTks0JG44Sw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch_10.pth\n",
            "/content/drive/My Drive/Colab Notebooks/Spring 21/NLP/Humour-Detection-2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2PibuK55tHw",
        "outputId": "e622ed2c-5ed2-432a-d2f3-71f7f1ad0132"
      },
      "source": [
        "#===============================================================================\n",
        "# Metrics on test data\n",
        "#===============================================================================\n",
        "ic(device)\n",
        "filename   = \"results_publictest_itr_4.csv\"\n",
        "test_loss, test_metrics = test1(model, testdata, device)\n",
        "print(' gold test loss: ', test_loss)\n",
        "print('gold test F1 score: ', test_metrics[0])\n",
        "print('gold test Accuracy: ', test_metrics[1])"
      ],
      "id": "v2PibuK55tHw",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| device: device(type='cuda')\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " gold test loss:  0.4038746981620789\n",
            "gold test F1 score:  0.9363416599516519\n",
            "gold test Accuracy:  0.921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVu3RyZBCzXn",
        "outputId": "0d809d27-0e71-4cf9-a357-76a8b275ed23"
      },
      "source": [
        ""
      ],
      "id": "fVu3RyZBCzXn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| test_loss: 0.4850126104354858\n",
            "ic| metrics: [0.9233278955954323, 0.906]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9233278955954323, 0.906]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}