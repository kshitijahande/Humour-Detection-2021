{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install pandas\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install icecream\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install nltk\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install plotly\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install pytorch_pretrained_bert pytorch-nlp\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install keras\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install tensorflow\n",
    "# ! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install transformers\n",
    "! /Users/kshitijahande/opt/anaconda3/envs/pytorch/bin/python -m pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7700ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "from tqdm.notebook import tqdm\n",
    "from icecream import ic \n",
    "\n",
    "import nltk\n",
    "# from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# imports from shudima\n",
    "# import torch\n",
    "# from pytorch_pretrained_bert import BertModel\n",
    "# from torch import nn\n",
    "# from torchnlp.datasets import imdb_dataset\n",
    "# from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "# imports from colbert\n",
    "# import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow import keras\n",
    "# from transformers import *\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# imports from shudima\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from torch.optim import Adam\n",
    "# from torch.nn.utils import clip_grad_norm_\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# import re\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init \n",
    "train_count = 1000 #8000\n",
    "# test_count = \n",
    "\n",
    "MAX_SENTENCE_LENGTH = 128 #colbert=20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing for BERT\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer.tokenize('Hi my nambe is Dima')\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.utils import *\n",
    "from ipynb.fs.full.datasets import *\n",
    "from ipynb.fs.full.architectures import *\n",
    "from ipynb.fs.full.train_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187df154",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\".\")\n",
    "\n",
    "# if seq length is 128 batch size should be 32\n",
    "traindata = torch.utils.data.DataLoader(dataset= Hahackathon(\"data/train.csv\", basenet= 'bert'), batch_size= 32, shuffle= True)\n",
    "# ic(\"Size of the dataset\",len(traindata.dataset))\n",
    "model = multitask_lstm_fc('bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.add_argument('--lr_max',            type = float,          default = 0.00002,      help = 'learning rate (default: 0.01)')\n",
    "learning_rate=0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e29a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score, accuracy_score\n",
    " \n",
    "# mse_criterion = torch.nn.MSELoss()\n",
    "ce_criterion  = torch.nn.CrossEntropyLoss()\n",
    "ic(ce_criterion)\n",
    "\n",
    "def concat_output1(output, device):\n",
    "    temp = torch.tensor([]).to(device)\n",
    "\n",
    "    if output.shape[1] == 2:\n",
    "        ic()\n",
    "        temp = torch.argmax(output[:, 0:2], dim=1).view(-1,1)\n",
    "        ic(temp)\n",
    "        return temp\n",
    "\n",
    "    temp = torch.argmax(output[:, 0:2], dim=1).view(-1,1)\n",
    "    temp = torch.cat((temp, torch.argmax(output[:, 2:4], dim= 1).view(-1,1)), dim= 1)\n",
    "    temp = torch.cat((temp, output[:, 4].view(-1,1)), dim= 1)\n",
    "    temp = torch.cat((temp, output[:, 5].view(-1,1)), dim= 1)\n",
    "    return temp\n",
    "\n",
    "def loss_func1(output, target, device):\n",
    "\n",
    "    humor_id = (target[:, 0]==1)\n",
    "    target   = target.float()\n",
    "    ic(output[:, 0:2])\n",
    "    \n",
    "    loss1 = ce_criterion(output[:, 0:2], target[:, 0].long())\n",
    "    loss=loss1\n",
    "    \n",
    "    # this block of generating temp is verified throughly\n",
    "    temp = concat_output1(output, device)\n",
    "    ic('outside concat_output ', temp)\n",
    "    temp = temp.detach()\n",
    "\n",
    "    return loss, temp\n",
    "\n",
    "def train1(model, dataloader, optimizer, device):\n",
    "#     ic('1')\n",
    "    model.train()\n",
    "#     ic('2')\n",
    "    train_loss = AverageMeter()\n",
    "\n",
    "    for batch_id, batch_data in enumerate(dataloader):\n",
    "        data       = batch_data[0]\n",
    "        target     = batch_data[1].to(device)\n",
    "#         ic(data)\n",
    "#         ic(target)\n",
    "\n",
    "        input_id   = data[0].to(device).squeeze()\n",
    "        mask_id    = data[1].to(device).squeeze()\n",
    "        segment_id = data[2].to(device).squeeze()\n",
    "#         ic(input_id)\n",
    "#         ic(mask_id)\n",
    "#         ic(segment_id)\n",
    "        \n",
    "        output = model(input_id, mask_id, segment_id)\n",
    "#         ic('output model')\n",
    "        \n",
    "        loss, _ = loss_func1(output, target, device= device)\n",
    "        ic('outside loss_func')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.update(loss.item(), target.shape[0])\n",
    "\n",
    "    return train_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3589bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1547b319d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ic(traindata)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "use_cuda= False\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# ic(traindata)\n",
    "# ic(optimizer)\n",
    "\n",
    "train_loss = train1(model, traindata, optimizer, device)\n",
    "ic(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07070e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
